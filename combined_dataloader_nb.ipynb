{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file\n",
      "Loaded 13793 rows.\n",
      "Normalizing features\n",
      "['GP', 'G', 'A', 'PTS', 'PS', 'EV', 'PP', 'S']\n",
      "Loading player data\n",
      "creating dataset structure\n",
      "creating player dict\n",
      "Targets\n",
      "['W%', 'L%', 'S']\n",
      "Normalizing features\n",
      "[]\n",
      "All features\n",
      "['W%', 'L%', 'GF/G', 'GA/G', 'PIM/G', 'oPIM/G', 'S', 'S%', 'SV%']\n",
      "Loading player data\n",
      "creating dataset structure\n"
     ]
    }
   ],
   "source": [
    "NL = [5]\n",
    "combined_dataset = get_combined_dataset(NL=NL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-1.4764, -1.4112, -1.1160, -1.2939, -0.9925, -1.3817, -0.7604, -1.4522,\n",
      "          0.7157, -0.8049,  0.3480, -0.2433, -1.0758, -1.2359,  0.4361,  0.3027,\n",
      "          0.6927],\n",
      "        [ 1.1718,  0.8535,  0.4189,  0.5992, -0.0528,  1.1265, -0.7604,  0.6668,\n",
      "         -0.2168,  0.4237, -0.7899, -0.1330, -1.1340, -1.0580,  0.7103, -1.2591,\n",
      "          0.1072],\n",
      "        [ 0.6775,  0.5288,  0.8122,  0.7104,  0.0797,  0.7669, -0.7604,  0.5590,\n",
      "          0.3187, -0.0570,  0.6034,  0.5289, -1.1146, -1.0580, -0.7661,  0.6315,\n",
      "         -0.4783],\n",
      "        [ 0.2891,  0.3069,  1.0182,  0.8073,  0.2849,  0.5212, -0.7604,  0.4570,\n",
      "          1.4441, -1.1209,  0.7195, -0.1330, -0.9595, -0.9789, -2.2486,  1.3712,\n",
      "          0.3581],\n",
      "        [ 0.5009,  0.7060,  0.6857,  0.6841,  0.3239,  0.8699,  0.0699,  0.6730,\n",
      "          1.6481, -1.2964,  1.9037,  0.3083, -0.5912, -0.6031,  1.0086,  1.3712,\n",
      "          0.0236]]), (tensor([[-1.4764, -1.4112, -1.1160, -1.2939, -0.9925, -1.3817, -0.7604, -1.4522],\n",
      "        [ 1.1718,  0.8535,  0.4189,  0.5992, -0.0528,  1.1265, -0.7604,  0.6668],\n",
      "        [ 0.6775,  0.5288,  0.8122,  0.7104,  0.0797,  0.7669, -0.7604,  0.5590],\n",
      "        [ 0.2891,  0.3069,  1.0182,  0.8073,  0.2849,  0.5212, -0.7604,  0.4570],\n",
      "        [ 0.5009,  0.7060,  0.6857,  0.6841,  0.3239,  0.8699,  0.0699,  0.6730]]), tensor([ 0.5009,  0.3069, -0.2151,  0.0491, -0.9253,  0.5212, -0.7604,  0.6014])))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# NOTE: we avoid contamination by training/testing with different players/teams\n",
    "N_datasets = combined_dataset.random_split(0.2)\n",
    "\n",
    "dataloaders_train = {}\n",
    "dataloaders_test ={}\n",
    "for Nd in N_datasets:\n",
    "    \n",
    "    # Set max_N to 0 to remove padding\n",
    "    dataset_train = TeamDataset(Nd[1],max_N=0)\n",
    "    dataset_test = TeamDataset(Nd[2],max_N=0)\n",
    "\n",
    "    # Must generate batches of sequence data with the following format:\n",
    "    # (batch_size, num_seasons(N), input_size(num stats))\n",
    "    # (https://stackoverflow.com/questions/49466894/how-to-correctly-give-inputs-to-embedding-lstm-and-linear-layers-in-pytorch/49473068#49473068)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    dataloaders_train[Nd[0]] = dataloader_train\n",
    "    dataloaders_test[Nd[0]] = dataloader_test\n",
    "\n",
    "print(dataset_train.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file\n",
      "Loaded 13793 rows.\n",
      "Normalizing features\n",
      "['GP', 'G', 'A', 'PTS', 'PS', 'EV', 'PP', 'S']\n",
      "Loading player data\n",
      "creating dataset structure\n",
      "creating player dict\n"
     ]
    }
   ],
   "source": [
    "# PLAYER DATASET\n",
    "player_dataset = get_player_dataset(NL=NL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEAM DATASET\n",
    "team_dataset = get_team_dataset(NL=[1]) # Only need one season (ensures all teams exists in dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'player_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 64\u001b[0m\n\u001b[0;32m      1\u001b[0m team_name_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFM\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAtlanta Flames\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMighty Ducks of Anaheim/Anaheim Ducks\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWSH\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWashington Capitals\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     60\u001b[0m }\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Append team features to player samples\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m player_df \u001b[38;5;241m=\u001b[39m \u001b[43mplayer_dataset\u001b[49m\u001b[38;5;241m.\u001b[39malldata\n\u001b[0;32m     65\u001b[0m team_df \u001b[38;5;241m=\u001b[39m team_dataset\u001b[38;5;241m.\u001b[39malldata\n\u001b[0;32m     67\u001b[0m samples_to_drop \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'player_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "team_name_dict = {\n",
    "    'AFM': 'Atlanta Flames',\n",
    "    'ANA': 'Mighty Ducks of Anaheim/Anaheim Ducks',\n",
    "    'ARI' : 'Arizona Coyotes',\n",
    "    'ATL' : 'Atlanta Thrashers',\n",
    "    'BOS' : 'Boston Bruins',\n",
    "    'BRK' : 'Brooklyn Americans',\n",
    "    'BUF' : 'Buffalo Sabres',\n",
    "    'CAR' : 'Carolina Hurricanes',\n",
    "    'CBJ' : 'Columbus Blue Jackets',\n",
    "    'CGS' : 'Bay Area Seals/California Golden Seals',\n",
    "    'CGY' : 'Calgary Flames',\n",
    "    'CHI' : 'Chicago Black Hawks/Blackhawks',\n",
    "    'CLE' : 'Cleveland Barons',\n",
    "    'CLR' : 'Colorado Rockies',\n",
    "    'COL' : 'Colorado Avalanche',\n",
    "    'DAL' : 'Dallas Stars',\n",
    "    'DCG' : 'Detroit Cougars',\n",
    "    'DET' : 'Detroit Red Wings',\n",
    "    'DFL' : 'Detroit Falcons',\n",
    "    'EDM' : 'Edmonton Oilers',\n",
    "    'FLA' : 'Florida Panthers',\n",
    "    'HAM' : 'Hamilton Tigers',\n",
    "    'HFD' : 'Hartford Whalers',\n",
    "    'KCS' : 'Kansas City Scouts',\n",
    "    'LAK' : 'Los Angeles Kings',\n",
    "    'MIN' : 'Minnesota Wild',\n",
    "    'MMR' : 'Montreal Maroons',\n",
    "    'MNS' : 'Minnesota North Stars',\n",
    "    'MTL' : 'Montreal Canadiens',\n",
    "    'MWN' : 'Montreal Wanderers',\n",
    "    'NJD' : 'New Jersey Devils',\n",
    "    'NSH' : 'Nashville Predators',\n",
    "    'NYA' : 'New York Americans',\n",
    "    'NYI' : 'New York Islanders',\n",
    "    'NYR' : 'New York Rangers',\n",
    "    'OAK' : 'California/Oakland Seals',\n",
    "    'OTT' : 'Ottawa Senators',\n",
    "    'PHI' : 'Philadelphia Flyers',\n",
    "    'PHX' : 'Phoenix Coyotes',\n",
    "    'PIR' : 'Pittsburgh Pirates',\n",
    "    'PIT' : 'Pittsburgh Penguins',\n",
    "    'QBD' : 'Quebec Bulldogs',\n",
    "    'QUA' : 'Philadelphia Quakers',\n",
    "    'QUE' : 'Quebec Nordiques',\n",
    "    'SEA' : 'Seattle Kraken',\n",
    "    'SEN' : 'Ottawa Senators (original)',\n",
    "    'SLE' : 'St. Louis Eagles',\n",
    "    'SJS' : 'San Jose Sharks',\n",
    "    'STL' : 'St. Louis Blues',\n",
    "    'TAN' : 'Toronto Hockey Club/Toronto Arenas',\n",
    "    'TBL' : 'Tampa Bay Lightning',\n",
    "    'TOR' : 'Toronto Maple Leafs',\n",
    "    'TSP' : 'Toronto St. Patricks',\n",
    "    'VAN' : 'Vancouver Canucks',\n",
    "    'VGK' : 'Vegas Golden Knights',\n",
    "    'WIN' : 'Winnipeg Jets (original)',\n",
    "    'WPG' : 'Winnipeg Jets',\n",
    "    'WSH' : 'Washington Capitals'\n",
    "}\n",
    "\n",
    "\n",
    "# Append team features to player samples\n",
    "player_df = player_dataset.alldata\n",
    "team_df = team_dataset.alldata\n",
    "\n",
    "samples_to_drop = []\n",
    "for player in player_dataset.data:\n",
    "    for N in player_dataset.data[player]:\n",
    "\n",
    "        # For each group \n",
    "        for year in player_dataset.data[player][N]:\n",
    "\n",
    "            # Find the team names for that group\n",
    "            player_data = player_df[player_df['Player'] == player]\n",
    "            player_data_year = player_data.loc[player_data['Season'].isin([season for season in range(year, year+N)])]\n",
    "            team_names = player_data_year['Tm'].values\n",
    "\n",
    "            # Get the team stats for each season\n",
    "            drop = 0\n",
    "            features = []\n",
    "            for season,team in enumerate(team_names):\n",
    "\n",
    "                if team not in team_name_dict:\n",
    "                    # drop sample and clean up\n",
    "                    drop = 1\n",
    "                    samples_to_drop.append((player, N, year))\n",
    "                    break\n",
    "\n",
    "                team_name = team_name_dict[team]\n",
    "\n",
    "                # Get normalized team data\n",
    "                team_data = team_dataset.all_data_normalized[team_dataset.all_data_normalized['team name'] == team_name]\n",
    "                team_data_year = team_data[team_data['Season'] == year+season]\n",
    "\n",
    "                if team_data_year.empty:\n",
    "                    # drop sample and clean up\n",
    "                    drop = 1\n",
    "                    samples_to_drop.append((player, N, year))\n",
    "                    break\n",
    "                \n",
    "                features.append(torch.tensor(team_data_year.drop(columns=['team name', 'Season'],axis=1).values, dtype=torch.float32))\n",
    "\n",
    "            if drop == 1:\n",
    "                continue\n",
    "\n",
    "            # Append the team stats to the player stats\n",
    "            try:\n",
    "                team_features = torch.stack(features).reshape((len(features), len(features[0][0]))) #features\n",
    "            except:\n",
    "                print(features)\n",
    "                exit(0)\n",
    "            player_features = player_dataset.data[player][N][year][0]\n",
    "            new_features = torch.hstack((player_features, team_features))\n",
    "            player_dataset.data[player][N][year] = (new_features , player_dataset.data[player][N][year][1])\n",
    "\n",
    "            print(player_dataset.data[player][N][year])\n",
    "\n",
    "# cleanup dataset\n",
    "for (player, N, year) in samples_to_drop:\n",
    "    player_dataset.data[player][N].pop(year, None)\n",
    "    if len(player_dataset.data[player][N]) == 0: # remove N if empty\n",
    "        player_dataset.data[player].pop(N, None)\n",
    "        if len(player_dataset.data[player]) == 0: # remove player if empty\n",
    "            player_dataset.data.pop(player, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
