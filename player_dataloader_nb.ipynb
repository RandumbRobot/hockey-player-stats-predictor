{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing the Player Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vQofphtmHg-b"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B89t_mtrIjrl"
      },
      "outputs": [],
      "source": [
        "# Data Paths\n",
        "file = './Data/player/processed/player_data.xlsx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ajuYr-4_InAk"
      },
      "outputs": [],
      "source": [
        "cols = [\n",
        "    'Rk', 'Player', 'Age', 'Tm', 'Pos', 'GP', 'G', 'A', 'PTS', '+/-', 'PIM',\n",
        "    'PS', 'EV', 'PP', 'SH', 'GW', 'EV.1', 'PP.1', 'SH.1', 'S', 'S%', 'TOI', 'ATOI', 'Season'\n",
        "]\n",
        "df = pd.read_excel(file, header=0, usecols=cols)\n",
        "\n",
        "df = df.replace('\\*', '', regex=True)\n",
        "df['original_index'] = df.index\n",
        "df = df.sort_values(by='GP', ascending=False)\n",
        "df = df.groupby(['Player', 'Age', 'Season']).filter(lambda x: x['GP'].max() > 47)\n",
        "df = df.drop_duplicates(subset=['Player', 'Age', 'Season'], keep='first')\n",
        "df = df.sort_values(by='original_index')\n",
        "df = df.drop(columns=['original_index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GiprUzunIvnR"
      },
      "outputs": [],
      "source": [
        "class PlayerDataset(Dataset):\n",
        "    def __init__(self, df, N=5, start_season=1990, stop_season=2023):\n",
        "        \"\"\"\n",
        "        Players dataset\n",
        "\n",
        "        :param df: DataFrame of preprocessed players dataset\n",
        "        :param N: number of consecutive seasons to load per player. The label will be the season N+1\n",
        "        :param start_season: first season to consider (inclusive)\n",
        "        :param stop_season: last season to consider (inclusive)\n",
        "        \"\"\"\n",
        "        self.N = N\n",
        "        self.start_season = start_season\n",
        "        self.stop_season = stop_season\n",
        "        self.alldata = df\n",
        "        self.data = self.load_player_data(self.alldata, self.start_season, self.stop_season, self.N)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_element = self.data[idx]\n",
        "        return data_element[0], data_element[1]\n",
        "\n",
        "    def set_seasons_per_group(self, N):\n",
        "        self.N = N\n",
        "        self.data = self.load_player_data(self.alldata, self.start_season, self.stop_season, self.N)\n",
        "\n",
        "    def load_player_data(self, df: pd.DataFrame, start_season: int, stop_season: int, N: int):\n",
        "        players = df['Player'].unique()\n",
        "        dataset = []\n",
        "\n",
        "        for player in players:\n",
        "            player_data = df[df['Player'] == player]\n",
        "            for season in range(start_season, stop_season - N + 2):\n",
        "                features = []\n",
        "                for s in range(season, season + N):\n",
        "                    season_data = player_data[player_data['Season'] == s]\n",
        "                    if season_data.empty:\n",
        "                        break\n",
        "                    features.append(season_data)\n",
        "\n",
        "                if len(features) != N:\n",
        "                    continue\n",
        "\n",
        "                target = player_data[player_data['Season'] == season + N]\n",
        "                if target.empty:\n",
        "                    continue\n",
        "\n",
        "                dataset.append([features, target])\n",
        "\n",
        "        return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1s-teJysI17V"
      },
      "outputs": [],
      "source": [
        "dataset = PlayerDataset(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt-U4vgCKpv9",
        "outputId": "235407f9-3197-4cb4-cef1-03b0f9d7d00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1055\n",
            "([        Rk       Player   Age   Tm Pos  GP   G   A  PTS  +/-  ...  SH  GW  \\\n",
            "11617  141  Zdeno Chára  36.0  BOS   D  77  17  23   40   25  ...   0   3   \n",
            "\n",
            "       EV.1  PP.1  SH.1    S    S%     TOI                 ATOI  Season  \n",
            "11617    17     5     1  168  10.1  1898.0  1900-01-01 00:39:00    2014  \n",
            "\n",
            "[1 rows x 24 columns],         Rk       Player   Age   Tm Pos  GP  G   A  PTS  +/-  ...  SH  GW  \\\n",
            "12125  150  Zdeno Chára  37.0  BOS   D  63  8  12   20    0  ...   0   0   \n",
            "\n",
            "       EV.1  PP.1  SH.1    S   S%     TOI      ATOI  Season  \n",
            "12125     8     1     3  138  5.8  1471.0  23:21:00    2015  \n",
            "\n",
            "[1 rows x 24 columns],         Rk       Player   Age   Tm Pos  GP  G   A  PTS  +/-  ...  SH  GW  \\\n",
            "12601  127  Zdeno Chára  38.0  BOS   D  80  9  28   37   12  ...   0   3   \n",
            "\n",
            "       EV.1  PP.1  SH.1    S   S%     TOI                 ATOI  Season  \n",
            "12601    17     9     2  158  5.7  1928.0  1900-01-01 00:06:00    2016  \n",
            "\n",
            "[1 rows x 24 columns],         Rk       Player   Age   Tm Pos  GP   G   A  PTS  +/-  ...  SH  GW  \\\n",
            "13109  136  Zdeno Chára  39.0  BOS   D  75  10  19   29   18  ...   2   0   \n",
            "\n",
            "       EV.1  PP.1  SH.1    S   S%     TOI      ATOI  Season  \n",
            "13109    17     2     0  136  7.4  1750.0  23:20:00    2017  \n",
            "\n",
            "[1 rows x 24 columns],         Rk       Player   Age   Tm Pos  GP  G   A  PTS  +/-  ...  SH  GW  \\\n",
            "13623  151  Zdeno Chára  40.0  BOS   D  73  7  17   24   22  ...   0   3   \n",
            "\n",
            "       EV.1  PP.1  SH.1    S   S%     TOI      ATOI  Season  \n",
            "13623    16     0     1  144  4.9  1672.0  22:54:00    2018  \n",
            "\n",
            "[1 rows x 24 columns]],         Rk       Player   Age   Tm Pos  GP  G  A  PTS  +/-  ...  SH  GW  EV.1  \\\n",
            "14132  161  Zdeno Chára  41.0  BOS   D  62  5  9   14   22  ...   0   2     7   \n",
            "\n",
            "       PP.1  SH.1   S   S%     TOI      ATOI  Season  \n",
            "14132     2     0  99  5.1  1307.0  21:05:00    2019  \n",
            "\n",
            "[1 rows x 24 columns])\n"
          ]
        }
      ],
      "source": [
        "dt = dataset.load_player_data(df, 1990, 2024, 5)\n",
        "print(dataset.__len__())\n",
        "print(dataset.__getitem__(0))\n",
        "#print(dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCzuCl2xLpZe",
        "outputId": "ee11843a-c03b-47f7-ef0e-18cc19f5314a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set length: 412\n",
            "Train set length: 3710\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "batch_size = 100\n",
        "test_length = len(dataset) // 10\n",
        "train_length = len(dataset) - test_length\n",
        "\n",
        "print(f\"Test set length: {test_length}\")\n",
        "print(f\"Train set length: {train_length}\")\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "dataset_test, dataset_train = random_split(dataset, [test_length, train_length])\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "    content_batch, title_batch = [], []\n",
        "\n",
        "    for (content, title) in data_batch:\n",
        "        content_tensors = [torch.tensor(c.values, dtype=torch.float) for c in content]\n",
        "        title_tensor = torch.tensor(title.values, dtype=torch.float)\n",
        "\n",
        "        content_batch.append(torch.cat(content_tensors, dim=0))\n",
        "        title_batch.append(title_tensor)\n",
        "\n",
        "    content_batch = pad_sequence(content_batch, padding_value=0.0, batch_first=True)\n",
        "    title_batch = pad_sequence(title_batch, padding_value=0.0, batch_first=True)\n",
        "\n",
        "    return content_batch, title_batch\n",
        "\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
